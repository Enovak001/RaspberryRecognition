{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1w_mpf0JFqGz4PVyrbgxFHZ7KMazQ3h8W",
      "authorship_tag": "ABX9TyPgMEvXyQRO3owE+AcBaEop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Enovak001/RaspberryRecognition/blob/main/object_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 👀✨🍇🍓 This notebook is Object Detector for Raspberry detection based on Kaggle dataset (https://www.kaggle.com/datasets/metavision/accurate-raspberry-shapessegmentation) and using Object detection model trained on Open Images V4 with ImageNet pre-trained Inception Resnet V2 as image feature extractor and/or EfficientDet/D7 Object detection model."
      ],
      "metadata": {
        "id": "nOhhdU9R8CGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Problem\n",
        "Predicting approximate quantity of raspberries on a field during one season by implementing images of a raspberry field, detecting and making prediction of a quantity.\n",
        "\n",
        "### 2. Task:\n",
        "Using object detection model, we will try to count raspberries on the images and predict yearly quantity.\n",
        "\n",
        "### 3. Data\n",
        "We will be using Kaggle dataset: \n",
        "* Accurate raspberry shapes/segmentation -> https://www.kaggle.com/datasets/metavision/accurate-raspberry-shapessegmentation\n",
        "\n",
        "### 4. Evaluation\n",
        "**Not possible!**\n",
        "\n",
        "We can evaluate only by checking with field owners and trust their experienced judgement.\n",
        "\n",
        "### 5. Extras\n",
        "\n",
        "We will be using:\n",
        "\n",
        "1. Object detection model trained on Open Images V4 with ImageNet pre-trained Inception Resnet V2 as image feature extractor.\n",
        "* https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\n",
        "\n",
        "2. EfficientDet Object detection model (SSD with EfficientNet-b7 + BiFPN feature extractor, shared box predictor and focal loss), trained on COCO 2017 dataset.\n",
        "* https://tfhub.dev/tensorflow/efficientdet/d7/1\n",
        "\n",
        "If detector turns out to be acceptable, we can use more sofisticate model EfficientDet/D7"
      ],
      "metadata": {
        "id": "CT8JV80yL3Pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the uploaded data into Google Drive\n",
        "#!unzip '/content/drive/MyDrive/Object Recognition Model/archive.zip' -d '/content/drive/MyDrive/Object Recognition Model/'"
      ],
      "metadata": {
        "id": "cYGO1gAuPFlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To read files from a directory\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join \n",
        "\n",
        "# To be able to use TensorFlow_Hub module:\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# To check availability of GPU devices (in total):\n",
        "from tensorflow.python.framework.config import list_physical_devices\n",
        "\n",
        "# For catching the images:\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imread\n",
        "%matplotlib inline\n",
        "# For loading images from web\n",
        "import tempfile\n",
        "\n",
        "# To have some math methods :)\n",
        "import math\n",
        "from math import ceil\n",
        "from random import seed\n",
        "from random import randint\n",
        "\n",
        "# For drawing on the image:\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "# To have possibility to check for a certain font\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For displaying an image:\n",
        "#from IPython.display import Image\n",
        "import pandas as pd\n",
        "\n",
        "# For measuring the inference time:\n",
        "import time\n",
        "\n",
        "# Print Tensorflow version\n",
        "print(f'TensorFlow version: {tf.__version__}')\n",
        "\n",
        "# Print Tensorflow version\n",
        "print(f'NumPy version: {np.__version__}')\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())\n",
        "\n",
        "# Check for GPU availability\n",
        "print('GPU', 'available (YEEEESSSSSS!!!!!) :)' if tf.config.list_physical_devices('GPU') else 'not available. Try later.. :(')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HfA-sZHTV3a",
        "outputId": "49c6d194-6099-4c08-8a55-5362d4019456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.2\n",
            "NumPy version: 1.21.6\n",
            "The following GPU devices are available: /device:GPU:0\n",
            "GPU available (YEEEESSSSSS!!!!!) :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's view an image\n",
        "###Image.open('/content/drive/MyDrive/Object Recognition Model/35-raspberry-01/720p/image00004061.jpg')"
      ],
      "metadata": {
        "id": "KfdsRA5FoZel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Differences between mentioned Object detection models:\n",
        "\n",
        "* 🟢 -> same feature for both models\n",
        "* 🟡 -> special feature for certain model\n",
        "\n",
        "\n",
        "1. **faster_rcnn/openimages_v4/inception_resnet_v2**\n",
        "\n",
        "  Inputs\n",
        "\n",
        "    * A three-channel image of variable size - the model does **NOT support batching**. The input tensor is a `tf.float32` tensor with shape `[1, height, width, 3]` with values in `[0.0, 1.0]`.🟡\n",
        "\n",
        "  Outputs\n",
        "\n",
        "    The output dictionary contains:\n",
        "\n",
        "      * detection_boxes: a `tf.float32` tensor of shape `[N, 4]` containing bounding box coordinates in the following order: `[ymin, xmin, ymax, xmax]`.🟢\n",
        "      * detection_class_entities: a `tf.string` tensor of shape `[N]` containing detection class names as Freebase MIDs.🟡\n",
        "      * detection_class_names: a `tf.string` tensor of shape `[N]` containing human-readable detection class names.🟡\n",
        "      * detection_class_labels: a `tf.int64` tensor of shape `[N]` with class indices.🟡\n",
        "      * detection_scores: a `tf.float32` tensor of shape `[N]` containing detection scores.🟢\n",
        "\n",
        "    https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\n",
        "\n",
        "2. **efficientdet/d7**\n",
        "\n",
        "  Inputs\n",
        "\n",
        "    * A three-channel image of variable size - the model **does NOT support batching**. The input tensor is a `tf.uint8` tensor with shape `[1, height, width, 3]` with values in `[0, 255]`.🟡\n",
        "\n",
        "  Outputs\n",
        "\n",
        "    The output dictionary contains:\n",
        "\n",
        "    * num_detections: a `tf.int` tensor with only one value, the number of detections `[N]`.🟡\n",
        "    * detection_boxes: a `tf.float32` tensor of shape `[N, 4]` containing bounding box coordinates in the following order: `[ymin, xmin, ymax, xmax]`.🟢\n",
        "    * detection_classes: a `tf.int` tensor of shape `[N]` containing detection class index from the label file.🟡\n",
        "    * detection_scores: a `tf.float32` tensor of shape `[N]` containing detection scores.🟢\n",
        "    * raw_detection_boxes: a `tf.float32` tensor of shape `[1, M, 4]` containing decoded detection boxes without Non-Max suppression. **M** is the number of raw detections.🟡\n",
        "    * raw_detection_scores: a `tf.float32` tensor of shape `[1, M, 90]` and contains class score logits for raw detection boxes. **M** is the number of raw detections.🟡\n",
        "    * detection_anchor_indices: a `tf.float32` tensor of shape `[N]` and contains the anchor indices of the detections after ***NMS***.🟡\n",
        "    * detection_multiclass_scores: a `tf.float32` tensor of shape `[1, N, 90]` and contains class score distribution (including background) for detection boxes in the image including background class.🟡\n",
        "\n",
        "    https://tfhub.dev/tensorflow/efficientdet/d7/1\n",
        "\n"
      ],
      "metadata": {
        "id": "VWLWh5KootgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with preparation for **efficientdet/d7**"
      ],
      "metadata": {
        "id": "w9PZ7EqupnVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our data ready and turning it into Tensors\n",
        "\n",
        "With all machine learning models, our data has to be in numerical format. So that's what we'll be doing first. Turnung our images into Tensors (numerical representation).\n",
        "Let's start by accesing our data."
      ],
      "metadata": {
        "id": "igH2vgCswgbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take all images into a list 'filenames'\n",
        "filenames = ['/content/drive/MyDrive/Object Recognition Model/35-raspberry-01/720p/' + fname for fname in os.listdir('/content/drive/MyDrive/Object Recognition Model/35-raspberry-01/720p')]"
      ],
      "metadata": {
        "id": "ntt0HrFxwToF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's see first 5 members\n",
        "# filenames[:5]"
      ],
      "metadata": {
        "id": "WHt_nZGHyYp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filenames[3]"
      ],
      "metadata": {
        "id": "UvEmupCCzNo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to get an image displayed\n",
        "###Image.open(filenames[156])"
      ],
      "metadata": {
        "id": "yVmGcDk6zRoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all images are in filenames\n",
        "if len(os.listdir('/content/drive/MyDrive/Object Recognition Model/35-raspberry-01/720p/'))==len(filenames):\n",
        "  print('Filenames match actual numbers of pictures. Proceed!')\n",
        "else:\n",
        "  print('Filenames does not match actual numbers of pictures. Error!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QCIb-iXzXKM",
        "outputId": "08750544-77da-4412-9444-55b3d0a61a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filenames match actual numbers of pictures. Proceed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesing images (turniung images into Tensors)\n",
        "\n",
        "To preprocess our images into Tensors we're going to write a function which does a few things:\n",
        "* Take an image filepath as input\n",
        "* Use TensorFlow to read the file and save it to a variable, `image`\n",
        "* Turn our `image` (a .jpg) into Tensors\n",
        "* Return modified `image`\n",
        "\n",
        "Before we do, let's see what importing image looks like."
      ],
      "metadata": {
        "id": "ZxHh-31c20te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Open the image with matplotlib\n",
        "# image = imread(filenames[42])"
      ],
      "metadata": {
        "id": "RdwKSNqg1CLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image.max(), image.min(), image.shape"
      ],
      "metadata": {
        "id": "NzXDJxIO21XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn image into tensor\n",
        "# tf.constant(image).shape, tf.constant(image).dtype"
      ],
      "metadata": {
        "id": "9PTgIXfS3TSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've seen what a image looks like as a Tensor, let's make a function to preprocess them.\n",
        "\n",
        "1. Take an image filepath as input\n",
        "2. Use TensorFlow to read the file and save it to a variable, `image`\n",
        "3. Turn our `image` (a .jpg) into Tensors\n",
        "4. Turn our picture into `tf.float32` format and with values 0-1 instead of 0-255\n",
        "5. Return modified `image`\n",
        "\n",
        "** We don't need to modify size of the pictures, because both of selected models are dealing with variable size image inputs."
      ],
      "metadata": {
        "id": "_UbfDIT-4-Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for preprocessing images\n",
        "def process_image(image_path):\n",
        "  '''\n",
        "  Takes the image filepath and turnes the image into a tensor.\n",
        "  '''\n",
        "  # Read a image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "\n",
        "  # Convert image to tensor\n",
        "  image = tf.convert_to_tensor(image)\n",
        "\n",
        "  # Turn the jpg image into numerical Tensor with 3 color channels (Red, Green, Blue)\n",
        "  # Adding a dimension tpo tensor to get `[1, height, width, 3]`\n",
        "  image = tf.image.decode_jpeg(image, channels=3)[tf.newaxis, ...]\n",
        "  \n",
        "  # Convert the colour channel values from 0-255 to 0-1 values\n",
        "  #image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "o7W8JJj_4F0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_data = process_image(filenames[42])"
      ],
      "metadata": {
        "id": "Ne83qT1ZLV0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_data.get_shape()"
      ],
      "metadata": {
        "id": "5qrep2-UO1YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have exactly what we need as input data for choosen detection model:\n",
        "**efficientdet/d7**\n",
        "* Inputs\n",
        "\n",
        "    * A **non-batched** set of three-channel images of variable size ✅. The input tensor is a `tf.uint8` ✅ tensor with shape `[1, height, width, 3]` ✅ with values in `[0, 255]` ✅."
      ],
      "metadata": {
        "id": "riVyi6iJ-6Kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Data\n"
      ],
      "metadata": {
        "id": "8WZeGxWVIcYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for viewing images in a data batch\n",
        "def show_25_images(images):\n",
        "  '''\n",
        "  Displays a plot of 25 images from data batch\n",
        "  '''\n",
        "  # Setup the figure\n",
        "  plt.figure(figsize=(12 , 10))\n",
        "\n",
        "  # Loop through 25 (for displaying 25 images)\n",
        "  for i in range(25):\n",
        "    # Create subplots (5 rows, 5 cols)\n",
        "    ax = plt.subplot(5, 5, i+1)\n",
        "    # Display a image\n",
        "    plt.imshow(process_image(images[i]))\n",
        "    # Add image label as the title\n",
        "    #plt.title(filenames[i][-17:-4])\n",
        "    plt.title(images[i][-17:])\n",
        "    plt.tight_layout(rect=[1.0,1.0,1.0,1.0])\n",
        "    # Turn the gridlines 'off'\n",
        "    plt.axis('off');"
      ],
      "metadata": {
        "id": "GXpYkr4vXlzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list(image_data.as_numpy_iterator())[:5]"
      ],
      "metadata": {
        "id": "YN37XTruYaGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rasp_images=(next(image_data.as_numpy_iterator()))"
      ],
      "metadata": {
        "id": "vW6BXaiahOAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's out our visualization\n",
        "###show_25_images(filenames)"
      ],
      "metadata": {
        "id": "Rhjb2HGZXsUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a model\n",
        "\n",
        "Before we build a model, there are few things we need to define:\n",
        "\n",
        "* The URL of the model we want to use - from TensorFlow Hub - https://tfhub.dev/tensorflow/efficientdet/d7/1"
      ],
      "metadata": {
        "id": "c2DdXNLUZ3CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Apply image detector on a single image.\n",
        "# detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/d7/1\")\n",
        "# detector_output = detector(image_data)\n",
        "# class_ids = detector_output[\"detection_classes\"]"
      ],
      "metadata": {
        "id": "u5k4ndyFYcsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply image detector on a single image\n",
        "def model_build(image_tensor, module_name):\n",
        "  #module_sample = \"https://tfhub.dev/tensorflow/efficientdet/d7/1\" #@param [\"https://tfhub.dev/tensorflow/efficientdet/d7/1\", \"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\", \"https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1\", \"https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1\", \"https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1\", \"https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1\"]\n",
        "  module_sample = module_name\n",
        "  detector = hub.load(module_sample)\n",
        "  detector_output = detector(image_tensor)\n",
        "  class_ids = detector_output[\"detection_classes\"]\n",
        "  return detector_output, module_sample"
      ],
      "metadata": {
        "id": "uuWGkqqdfCtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#im1 = model_build(process_image(filenames[24]))"
      ],
      "metadata": {
        "id": "DU-N1vuOQ0nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#detector_output['detection_multiclass_scores']"
      ],
      "metadata": {
        "id": "GisF2zGSgT1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#detector_output[\"detection_classes\"].numpy()[0][5]"
      ],
      "metadata": {
        "id": "QnCBYwh2LASo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#detector_output[\"num_detections\"].numpy()[0]"
      ],
      "metadata": {
        "id": "x_nA0xpNwYIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(detector_output[\"detection_classes\"].numpy()[0])"
      ],
      "metadata": {
        "id": "BvA1m4ba4I02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(image, fig_name):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)\n",
        "  plt.savefig('/content/drive/MyDrive/Object Recognition Model/pics/'+fig_name)"
      ],
      "metadata": {
        "id": "zCvF4uT3vBqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import MAX_CACHE_SIZE\n",
        "# let's draw some boxes on our images.\n",
        "def draw_box_per_detection(image,\n",
        "                           ymin, xmin, ymax, xmax,\n",
        "                           color,\n",
        "                           font,\n",
        "                           thickness=3,\n",
        "                           display_str_list=()):\n",
        "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
        "  frame = ImageDraw.Draw(image)\n",
        "  im_width, im_height = image.size\n",
        "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
        "                                ymin * im_height, ymax * im_height)\n",
        "  frame.line([(left, top), (left, bottom), (right, bottom), (right, top), (left, top)],\n",
        "            width=thickness,\n",
        "            fill=color)\n",
        "\n",
        "  # If the total height of the display strings added to the top of the bounding\n",
        "  # box exceeds the top of the image, stack the strings below the bounding box\n",
        "  # instead of above.\n",
        "  display_str_heights = [font.getsize(d_s)[1] for d_s in display_str_list]\n",
        "  # Each display_str has a top and bottom margin of 0.05x.\n",
        "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
        "\n",
        "  if top > total_display_str_height:\n",
        "    text_bottom = top\n",
        "  else:\n",
        "    text_bottom = top + total_display_str_height\n",
        "  # Reverse list and print from bottom to top.\n",
        "  for display_str in display_str_list[::-1]:\n",
        "    text_width, text_height = font.getsize(display_str)\n",
        "    margin = np.ceil(0.05 * text_height)\n",
        "    frame.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
        "                    (left + text_width, text_bottom)],\n",
        "                   fill=color)\n",
        "    frame.text((left + margin, text_bottom - text_height - margin),\n",
        "              display_str,\n",
        "              fill=\"black\",\n",
        "              font=font)\n",
        "    text_bottom -= text_height - 2 * margin"
      ],
      "metadata": {
        "id": "mhYGROwIgu_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UFxKAzwCGpfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image = Image.open(filenames[42])\n",
        "# imag = Image.fromarray(np.asarray(image), mode=\"RGB\")\n",
        "# im_width, im_height = imag.size\n",
        "# im_width, im_height"
      ],
      "metadata": {
        "id": "vxzULqOksvsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_boxes(image, min_score, num_detections,\n",
        "                                detection_boxes, \n",
        "                                detection_scores, \n",
        "                                detection_classes, \n",
        "                                raw_detection_boxes,\n",
        "                                raw_detection_scores,\n",
        "                                detection_anchor_indices,\n",
        "                                detection_multiclass_scores,\n",
        "                                max_boxes=30):\n",
        "  seed(42)\n",
        "  '''Places a label boxes on a image, based on formated scores and values(classes).'''\n",
        "  colors = list(ImageColor.colormap.values())\n",
        "  font = ImageFont.load_default()\n",
        "  # We can not copy anything to 'image', so we're making a copy of 'image'\n",
        "  temp_img = np.empty_like(image)\n",
        "  np.copyto(temp_img, image)\n",
        "  count = 0\n",
        "  for i in range(min(max_boxes, num_detections.numpy()[0])):\n",
        "    if (detection_scores.numpy()[0][i] >= min_score) and (detection_classes.numpy()[0][i] == 53):\n",
        "      color = colors[randint(0,len(colors))]\n",
        "      ymin, xmin, ymax, xmax = detection_boxes.numpy()[0][i]\n",
        "      text_frame = '{}: {:.1f}%'.format('Fruits',\n",
        "                                      int(detection_scores.numpy()[0][i]*100))\n",
        "      image_pil = Image.fromarray(temp_img, mode=\"RGB\")\n",
        "      draw_box_per_detection(image_pil, \n",
        "                            ymin, xmin, ymax, xmax,\n",
        "                            color,\n",
        "                            font,\n",
        "                            display_str_list=[text_frame])\n",
        "      count += 1\n",
        "      np.copyto(temp_img, np.array(image_pil))\n",
        "      #np.copyto(image, image_pil)\n",
        "  print(f\"Marked {count} objects.\")\n",
        "  return temp_img, count"
      ],
      "metadata": {
        "id": "csOiDTqXlcT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we need our image to be able to enter a model to be processed, turned into Tensors so we can use it in our 'detector'."
      ],
      "metadata": {
        "id": "zw_KyKFiq5Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process image and run through 'detector'\n",
        "def run_detector(path, model_name, min_score):\n",
        "  image = process_image(path)\n",
        "  \n",
        "  start_time = time.time()\n",
        "  detected_image, module_sample = model_build(image, model_name)\n",
        "  end_time = time.time()\n",
        "  tot_time = end_time - start_time\n",
        "\n",
        "  print(\"Inference time: \", tot_time)\n",
        "  print(f\"Found {len(detected_image['detection_scores'].numpy()[0])} objects.\")\n",
        "\n",
        "  image_with_boxes, count = draw_boxes(np.asarray(tf.squeeze(image)), min_score, **detected_image)\n",
        "  fig_name = module_sample[29:].replace('/','_') + '_Marked_' + str(count) + '_objects_'+path[-17:]\n",
        "  \n",
        "  display_image(image_with_boxes, fig_name)\n",
        "\n",
        "  return detected_image['detection_scores'].numpy()[0], count, tot_time"
      ],
      "metadata": {
        "id": "oXTfoH4Aq24v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pic = 3456\n",
        "# model_name = 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1'\n",
        "# run_detector(filenames[pic], model_name)"
      ],
      "metadata": {
        "id": "NbufjOVCvkI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(loops):\n",
        "  min_score = 0.1\n",
        "  columns = ['Model', 'Interence_Time[s]', 'No._of_Found_Objects', f'Objects_with_min_{min_score*100}%_accurance']  \n",
        "  df_all_models = pd.DataFrame(columns = columns)\n",
        "  pd.set_option('display.max_colwidth', None)\n",
        "  for i in range(loops):\n",
        "    pic = randint(0,len(filenames))\n",
        "    model_name = [\"https://tfhub.dev/tensorflow/efficientdet/d7/1\", \n",
        "                  \"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\", \n",
        "                  \"https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1\", \n",
        "                  \"https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1\", \n",
        "                  \"https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1\", \n",
        "                  \"https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1\"]\n",
        "    for model in model_name:\n",
        "      score, no_of_objects, tot_time = run_detector(filenames[pic], model, min_score)\n",
        "      df_all_models.loc[len(df_all_models.index)] = [model[29:].replace('/','_')+'_'+filenames[pic][-17:], '%.2f' % tot_time, len(score), no_of_objects]\n",
        "      df_all_models.to_csv('/content/drive/MyDrive/Object Recognition Model/model_comparison.csv',index=False)\n",
        "  return df_all_models\n",
        "  "
      ],
      "metadata": {
        "id": "gEsDL-V3q344"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AWud-4VSxH1r",
        "outputId": "884103e1-35fc-4271-b069-b7ecee02e933"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}